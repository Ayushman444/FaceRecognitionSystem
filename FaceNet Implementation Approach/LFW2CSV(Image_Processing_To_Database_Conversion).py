# -*- coding: utf-8 -*-
"""Untitled49.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dK-N4NxDlAXnVCwnrkn8DgwZj8_1QqQB
"""

!rm -rf /content/.cache && rm -rf /tmp/*
from google.colab import drive

drive.mount('/content/drive')

import zipfile

with zipfile.ZipFile('/content/drive/MyDrive/archive.zip', 'r') as zip_ref:
  zip_ref.extractall('/content/')

drive.flush_and_unmount()

import pandas as pd
from sklearn.model_selection import train_test_split

# Load the LFW dataset (assuming you've downloaded it)
df = pd.read_csv('lfw_allnames.csv')  # Adjust the file path as needed

# Split the dataset into training and testing sets (e.g., 80% train, 20% test)
train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)

# Check the shapes of the resulting dataframes
print("Training set shape:", train_df.shape)
print("Testing set shape:", test_df.shape)

import pandas as pd
import cv2
import numpy as np
import os

# Initialize an empty DataFrame with column names
cols = ['image', 'person']
trainSet = pd.DataFrame(columns=cols)

def processImg(path_of_folder):
    face_classifier = cv2.CascadeClassifier('/content/haarcascade_frontalface_default.xml')
    paths = os.listdir(path_of_folder)
    imageArr = []
    classes = []
    count = 0

    for path_of_img in paths:
        varis = path_of_img
        path_of_img = str(path_of_folder + "/" + path_of_img)
        image = cv2.imread(path_of_img)
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        try:
            (x, y, w, h) = face_classifier.detectMultiScale(gray, 1.3, 5)[0]
        except:
            count+=1
            continue

        image = image[y:y+h, x:x+w, :]
        cv2.resize(image, (224, 224))
        img = np.asarray(image)
        img = img.astype('float32') / 255.0
        img = np.expand_dims(img, axis=0)
        imageArr.append(img)

        l = varis.split('.')
        l[0] = l[0].replace('_', ' ')
        l[0] = l[0][:len(l[0]) - 5]
        classes.append(l[0])

        return (classes,imageArr,count)

inter = '/content/lfw-deepfunneled/lfw-deepfunneled/'

all_images = []
all_classes = []
netRem = 0
for i in train_df.name:
  try:
    classes,imageArr,count = processImg(inter+i)
    all_classes.extend(classes)
    all_images.extend(imageArr)
    netRem = netRem + count
  except:
    continue
print('removed image: ',netRem)
all_classes

trainSet['image'] = all_images
trainSet['person'] = all_classes

trainSet.to_csv("processed_data.csv", index=False)

import pandas as pd
import cv2
import numpy as np
import os

# Initialize an empty DataFrame with column names
cols = ['image', 'person']
testSet = pd.DataFrame(columns=cols)

def processImg(path_of_folder):
    face_classifier = cv2.CascadeClassifier('/content/haarcascade_frontalface_default.xml')
    paths = os.listdir(path_of_folder)
    imageArr = []
    classes = []
    count = 0

    for path_of_img in paths:
        varis = path_of_img
        path_of_img = str(path_of_folder + "/" + path_of_img)
        image = cv2.imread(path_of_img)
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        try:
            (x, y, w, h) = face_classifier.detectMultiScale(gray, 1.3, 5)[0]
        except:
            count+=1
            continue

        image = image[y:y+h, x:x+w, :]
        cv2.resize(image, (224, 224))
        img = np.asarray(image)
        img = img.astype('float32') / 255.0
        img = np.expand_dims(img, axis=0)
        imageArr.append(img)

        l = varis.split('.')
        l[0] = l[0].replace('_', ' ')
        l[0] = l[0][:len(l[0]) - 5]
        classes.append(l[0])

        return (classes,imageArr,count)

inter = '/content/lfw-deepfunneled/lfw-deepfunneled/'

all_images = []
all_classes = []
netRem = 0
for i in test_df.name:
  try:
    classes,imageArr,count = processImg(inter+i)
    all_classes.extend(classes)
    all_images.extend(imageArr)
    netRem = netRem + count
  except:
    continue
print('removed image: ',netRem)
all_classes

testSet['image'] = all_images
testSet['person'] = all_classes

testSet.to_csv("processed_data_test.csv", index=False)